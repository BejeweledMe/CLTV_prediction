CLTV Prediction

### Постановка задачи
Решить типичную для продуктовой аналитики задачу прогноза LTV пользователя. 

Для этого необходимо:
1) провести исследовательский анализ данных,
2) визуализировать результаты и сделать из них выводы, 
3) провести предобработку признаков (возможно создать новые),
4) обучить модели, и подобрать для каждой из них оптимальные гиперпараметры,
5) оценить работу моделей и сравнить их между собой, выбрать итоговую и объяснить свой выбор
6) проинтерпретировать получившиеся результаты (что и как влияет на LTV пользователя)

### Данные
В файле LTV.csv представлены данные о пользователях с автомобильной страховкой, собранных системой аналитики компании IBM.

Описание данных:
* Customer - идентификатор пользователя
* State - штат
* Customer Lifetime Value - LTV пользователя
* Response - взаимодействие с рекламой
* Coverage - тип страхового покрытия
* Education - образование
* Effective to date - срок действия страховки
* EmploymentStatus - трудоустройство
* Gender - пол
* Income - доход
* Location code - тип местности в которой проживает пользователь
* Marital Status - семейное положение
* Monthly Premium Auto 
* Months Since Last Claim - месяцев с последнего требования по выплате компенсации
* Months Since Policy Inception - месяцев с открытия страховки
* Number of Open Complaints - количество незакрытых жалоб
* Number of Policies - количество полисов
* Policy Type - тип страховки
* Policy - страховка
* Renew Offer Type - обновленный тип предложения
* Sales Channel - канал продаж
* Total Claim Amount - сумма выплаченных компенсаций
* Vehicle Class - класс автомобиля
* Vehicle Size - размер автомобиля

# Решение
1) Анализ данных выполнен в `EDA.ipynb`, также его можно посмотреть в `EDA.pdf`
2) Функции для предобработки признаков находятся в `preprocessing.py`, 
   предобработка и разделение на тренировочную и отложенную выборку в `get_train_test_data.py`
3) Для сравнения были выбраны 4 модели, а именно:
    * Линейная регрессия
    * Случайный лес
    * Градиентный бустинг XGBoost
    * Нейронная сеть

    *Модели выбирались разного типа, чтобы лучше сравнить между собой алгоритмы (а не сравнивать между собой разные виды бустингов, как пример)*

## Метрики
*Метрики замерены на отложенной выборке и округлены до 3 плавающего знака*

### Линейная Регрессия
У линейной регрессии самый плохой результат - **RMSLE: 0.556** на всех признаках и ещё хуже, если строить предсказания по одному признаку

### Случайный Лес
Блендинг моделей случайного леса из CV (Кросс-Валидации) дал **RMSLE: 0.194**, в то время как одиночная модель, обученная на полном сете тренировочных данных, дала **RMSLE: 0.191**

### XGBoost
Блендинг моделей бустинга из CV дал **RMSLE: 0.195**

### Нейронная сеть
Блендинг **нейронных сетей** из CV дал **RMSLE: 0.218**

## Важность признаков
*Графики с важностью признаков можно посмотреть в `modeling.ipynb`*

**Линейная регрессия** показала лучший счёт при помощи `Monthly Premium Auto`, но в показатели по признакам не сильно отличаются.

Остальные же модели показали примерно одинаковую важность признаков, а именно:
* На первом месте `Number of Policies` с отрывом в несколько раз от второго места
* На втором месте `Monthly Premium Auto`
* Остальные признаки имеют малую важность

## Итог
Лучше всего себя показал **случайный лес**, обученный без кросс-валидаци на всём тренировочном сете с **RMSLE: 0.191**
